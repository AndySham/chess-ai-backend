{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166906fb",
   "metadata": {},
   "source": [
    "# Fuzzy Conjunctions\n",
    "\n",
    "This section aims to show that Fuzzy Logic architectures are adept at learning conjunctions (and disjunctions) as a subset of the problem of learning general boolean functions using neurosymbolic methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3754f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src')) # include top level package in python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4592bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model.fuzzy_layer import FuzzyUnsignedConjunction, FuzzyUnsignedDisjunction\n",
    "from model.fuzzy_logic import ProductLogic, MinimumLogic, LukasiewiczLogic, SchweizerSklarLogic\n",
    "from model.bool_logic import BoolLogic\n",
    "from plot import gauss_filter\n",
    "from cache import FileCacher\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "logic = BoolLogic()\n",
    "cacher = FileCacher('./conjunction_grads/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde43f5",
   "metadata": {},
   "source": [
    "We begin by defining our training distribution, which will be a distribution over $N$ variables, each of which being independently sampled from a Bernoulli distribution $\\textsf{Ber}(0.5)$, i.e. we evenly sample points from the boolean hypercube $\\{0,1\\}^N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1f2ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "\n",
    "class BinaryDataset(Dataset):\n",
    "    def __init__(self, shape, N):\n",
    "        self.samples = torch.distributions.bernoulli.Bernoulli(\n",
    "            0.5\n",
    "        ).sample(\n",
    "            torch.Size([N, *shape])\n",
    "        ).bool()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.samples.size(0)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b59d4ae",
   "metadata": {},
   "source": [
    "Here we define a dataset of 1024 samples with $N=10$. We will sample over the dataset 10,000 times per epoch, with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "510357ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = BinaryDataset([10], 10_000)\n",
    "ds = BinaryDataset([10], 1_000)\n",
    "sampler = RandomSampler(ds, replacement=True, num_samples=100_000)\n",
    "loader = DataLoader(ds, batch_size=128, sampler=sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ff60a7",
   "metadata": {},
   "source": [
    "We want to learn membership $W$ of a conjunction. To generate conjunctions, we again sample elements of the boolean hypercube $\\{0,1\\}^N$ to encode the corresponding membership set. A conjunction with membership set $|W|=D$ will be satisfied with probability $2^{-D}$ over evenly distributed boolean vectors, so we will specify that $D = 4$, so as to tractably generate data of both the satisfied and unsatisfied cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96042504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_n_true(shape, N):\n",
    "    falses = torch.zeros(shape, dtype=torch.bool)\n",
    "    falses = falses.view(-1)\n",
    "    falses[:N] = True\n",
    "    falses = falses[torch.randperm(falses.size(0))]\n",
    "    return falses.view(*shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e775322",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_10 = cacher.cache('weight-10', lambda: rand_n_true([10], 4))\n",
    "weights_100 = cacher.cache('weight-100', lambda: rand_n_true([100], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353bc39b",
   "metadata": {},
   "source": [
    "We define our model to be that of a fuzzy conjunction with learnable membership parameters $\\tilde{\\mathbf{w}}$. We will use the Product logic as our system of fuzzy logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df9e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e710960e",
   "metadata": {},
   "source": [
    "Firstly, we will examine the gradient estimators generated by the model. We hope to relate these gradients to logical inferences which can be made in classical logic.\n",
    "\n",
    "In classical logic, we can infer the value of $\\mathbf{w}$ by recognising that for conjunction $\\phi_\\mathbf{w}$, input $\\mathbf{x}$, we know that if $\\phi_\\mathbf{w}(\\mathbf{x}) = \\mathbf{T}$, then all variables in $\\mathbf{x}$ that are present in the conjunction are also true. Formally, this means that for all $i \\in \\{1,\\ldots,N\\}, w_i = \\mathbf{T} \\implies x_i = \\mathbf{T}$. The contrapositive of this is that $x_i = \\mathbf{F} \\implies w_i = \\mathbf{F}$. Thus;\n",
    "\n",
    "$$\n",
    "(\\phi_W(\\mathbf{x}) = \\mathbf{T} \\land x_i = \\mathbf{F}) \n",
    "\\implies w_i = \\mathbf{F}\n",
    "$$\n",
    "\n",
    "To fully determine $\\mathbf{w}$, we need only sample $\\mathbf{x}$ from a distribution with adequate support.\n",
    "\n",
    "This process would be captured in a Fuzzy Logic model by observing it in the gradient estimator. For observed input $\\mathbf{x}$, model parameters $\\tilde{\\mathbf{w}}$, and observed output $\\mathbf{T}$, we would hope to see a gradient that would result in SGD pursuing $\\tilde{w}_i$ closer to $0$ for $i$ such that $x_i = \\mathbf{F}$. This could be achieved if we find that, for some loss function $\\ell$, \n",
    "\n",
    "$$\\frac{\\partial \\ell}{\\partial \\tilde{w}_i} \\propto \\tilde{w}_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ad0ca9",
   "metadata": {},
   "source": [
    "Let us calculate an analytical solution for $\\frac{\\partial \\ell}{\\partial \\tilde{\\mathbf{w}}}$ in the case of the Product Logic. We capture the model as a function $h:[0,1]^N \\to [0,1]$, where $h(\\mathbf{x}) = \\bigotimes \\left[\\tilde{\\mathbf{w}} \\Rightarrow \\mathbf{x}\\right]$. In product logic, $a \\otimes b = ab$, and $a \\Rightarrow b = 1 - a+ab$, so $h(\\mathbf{x}) = \\prod_i \\left[1 - \\tilde{w}_i + \\tilde{w}_ix_i\\right]$.\n",
    "\n",
    "Thus $\\frac{\\partial h}{\\partial \\tilde{w}_i} = (x_i - 1)\\prod_{j \\neq i}\\left[1 - \\tilde{w}_j + \\tilde{w}_jx_j\\right]$. Let $c = \\prod_{j \\neq i}\\left[1 - \\tilde{w}_j + \\tilde{w}_jx_j\\right]$. Note that $c$ is the result of a boolean function in a Fuzzy Logic, so its value is in $[0,1]$. \n",
    "\n",
    "Let us consider the MSE loss function, i.e. $\\ell(\\mathbf{x}, y; \\tilde{\\mathbf{w}}) = (h(\\mathbf{x}) - y)^2$. We get \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial\\ell}{\\partial\\tilde{w}_i}\n",
    "&= 2 (h(\\mathbf{x}) - y) \\cdot \\frac{\\partial h}{\\partial \\tilde{w}_i} \\\\\n",
    "&= 2 ((1 - \\tilde{w}_i + \\tilde{w}_ix_i)c - y)(x_i - 1)c \\\\\n",
    "&= 2c^2\\tilde{w}_i + 2c(1-c) \\text{, for assumption $x_i = 0, y = 1$.}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "As $c \\in [0,1]$, $2c(1-c) \\in [0,\\frac{1}{2}]$. Thus this satisfies our intitial requirements, in that the gradient is positive and increases linearly with $\\tilde{w}_i$. The quality of the gradient becomes better the closer $c$ is to $1$, i.e. the more the remaining variables $j\\neq i$ contribute to the final output $y=1$. The intuition behind this is that the more membership values $\\tilde{\\mathbf{w}}$ are misassigned, the more the quality of the gradient for individual parameters decreases. However, we also find that, if $x_i = 1$, the gradient $\\frac{\\partial \\ell}{\\partial \\tilde{w}_i} = 0$, therefore the valuation of our parameters only improves with true output $y = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b832e722",
   "metadata": {},
   "source": [
    "Intuition therefore tells us that performing SGD on the above model should simulate the inferences that can be made in pure logic. The true gradients, however, are expected values of the gradient estimator $\\frac{\\partial \\ell}{\\partial \\tilde{\\mathbf{w}}}$ over the incoming probability distribution, therefore we must still verify that the the appropriate inferences are being made. To do this we plot, over all possible values $\\tilde{ \\mathbf{w}}$, samples of the gradient estimator. We will empirically show that the expected value is as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed9f5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grad import GradSampler\n",
    "\n",
    "\n",
    "def get_samples(flogic, weights, name, exp=2):\n",
    "    cj_model = FuzzyUnsignedConjunction(in_features=weights.size(0), out_features=1, logic=flogic)\n",
    "    ds = BinaryDataset([weights.size(0)], 10_000)\n",
    "    sampler = RandomSampler(ds, replacement=True, num_samples=1_000_000 // weights.size(0))\n",
    "    loader = DataLoader(ds, batch_size=128, sampler=sampler)\n",
    "    \n",
    "    def get_loss(bs):\n",
    "        cjs = logic.conjoin(logic.implies(weights, bs), dim=1)\n",
    "        cj_hats = cj_model(flogic.encode(bs)).squeeze()\n",
    "        return ((cjs.float() - cj_hats).abs() ** exp).sum()\n",
    "\n",
    "    def refresh_weights():\n",
    "        cj_model.weights.reinitialize()\n",
    "    \n",
    "    def f():\n",
    "        grad_sampler = GradSampler(get_loss, cj_model.parameters(), on_loop=refresh_weights)\n",
    "        grad_sampler.loop(tqdm(loader, desc=\"Sampling Gradients [%s]\" % name, leave=False))\n",
    "        return (\n",
    "            grad_sampler.inputs, \n",
    "            grad_sampler.outputs, \n",
    "            grad_sampler.param_values[0].squeeze(),\n",
    "            grad_sampler.grads[0].squeeze(),\n",
    "        )\n",
    "        \n",
    "    return f\n",
    "    \n",
    "prod = cacher.cache('product', get_samples(ProductLogic(), weights_10, \"Product\"))\n",
    "luk = cacher.cache('lukasiewicz', get_samples(LukasiewiczLogic(), weights_10, \"Lukasiewicz\"))\n",
    "minimum = cacher.cache('minimum', get_samples(MinimumLogic(), weights_10, \"Minimum\"))\n",
    "ss = cacher.cache('ss', get_samples(SchweizerSklarLogic(torch.tensor(-2.0)), weights_10, \"Schweizer-Sklar\"))\n",
    "    \n",
    "prod_1 = cacher.cache('product-1', get_samples(ProductLogic(), weights_10, \"Product 1\", 1))\n",
    "luk_1 = cacher.cache('lukasiewicz-1', get_samples(LukasiewiczLogic(), weights_10, \"Lukasiewicz 1\", 1))\n",
    "minimum_1 = cacher.cache('minimum-1', get_samples(MinimumLogic(), weights_10, \"Minimum 1\", 1))\n",
    "ss_1 = cacher.cache('ss-1', get_samples(SchweizerSklarLogic(torch.tensor(-2.0)), weights_10, \"Schweizer-Sklar 1\", 1))\n",
    "    \n",
    "prod_10 = cacher.cache('product-10', get_samples(ProductLogic(), weights_10, \"Product 10\", 10))\n",
    "luk_10 = cacher.cache('lukasiewicz-10', get_samples(LukasiewiczLogic(), weights_10, \"Lukasiewicz 10\", 10))\n",
    "minimum_10 = cacher.cache('minimum-10', get_samples(MinimumLogic(), weights_10, \"Minimum 10\", 10))\n",
    "ss_10 = cacher.cache('ss-10', get_samples(SchweizerSklarLogic(torch.tensor(-2.0)), weights_10, \"Schweizer-Sklar 10\", 10))\n",
    "\n",
    "prod_dim100 = cacher.cache('product-dim100', get_samples(ProductLogic(), weights_100, \"Product Dim100\", 1))\n",
    "#luk = cacher.cache('lukasiewicz-dim100', get_samples(LukasiewiczLogic(), weights_100, \"Lukasiewicz Dim100\", 1))\n",
    "#minimum = cacher.cache('minimum-dim100', get_samples(MinimumLogic(), weights_100, \"Minimum Dim100\", 1))\n",
    "#ss = cacher.cache('ss-dim100', get_samples(SchweizerSklarLogic(torch.tensor(-2.0)), weights_100, \"Schweizer-Sklar Dim100\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db960170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sig_prime(xs):\n",
    "    sig = torch.sigmoid(xs)\n",
    "    return sig * (1 - sig)\n",
    "\n",
    "def plot_grads(params, grads, ax, multiplier=None, no_points=False):\n",
    "    # the model actually learns over parameters in R, then maps to [0,1]\n",
    "    norm_params = torch.sigmoid(params) \n",
    "    norm_grads = grads / sig_prime(params)\n",
    "    \n",
    "    if not no_points:\n",
    "        ax.scatter(norm_params, norm_grads, s=5, alpha=0.1, color=\"indigo\")\n",
    "        \n",
    "    xs = torch.linspace(0, 1, 150)\n",
    "    ax.set_xlim(0,1)\n",
    "    if not no_points: \n",
    "        ax.set_ylim(norm_grads.nan_to_num(0).min(), norm_grads.nan_to_num(0).max())\n",
    "    if multiplier is not None:\n",
    "        norm_grads *= multiplier.unsqueeze(-1)\n",
    "    ax.plot(xs, gauss_filter(xs, norm_params.view(-1), norm_grads.view(-1), 0.003), color=\"fuchsia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6aa128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grads_restricted(grad_cache, weights, true_output, true_param, ax, mutiplier=False, no_points=False):\n",
    "    inputs, _, params, grads = grad_cache\n",
    "    true_outputs = logic.conjoin(logic.implies(weights, inputs), dim=1)\n",
    "    \n",
    "    if true_output is None:\n",
    "        output_idx = torch.ones_like(true_outputs).bool()\n",
    "    else:\n",
    "        output_idx = true_outputs == true_output\n",
    "        \n",
    "    if true_param is None:\n",
    "        weight_idx = torch.ones_like(weights).bool()\n",
    "    else:\n",
    "        weight_idx = weights == true_param\n",
    "        \n",
    "    \n",
    "    params = params[output_idx][:,weight_idx]\n",
    "    grads = grads[output_idx][:,weight_idx]\n",
    "    \n",
    "    multiplier_weighting = None\n",
    "    if mutiplier and true_output is None:\n",
    "        multiplier_weighting = torch.ones(grads.size(0))\n",
    "        multiplier_weighting[true_outputs] /= true_outputs.sum()\n",
    "        multiplier_weighting[true_outputs == False] /= (true_outputs == False).sum()\n",
    "    \n",
    "    plot_grads(params, grads, ax, multiplier=multiplier_weighting, no_points=no_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0fcddb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plot_grads_restricted(prod_dim100, weights_100, None, False, ax, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d114942d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grad_sampler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_sampler\u001b[49m\u001b[38;5;241m.\u001b[39mparam_values[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m      2\u001b[0m grads \u001b[38;5;241m=\u001b[39m grad_sampler\u001b[38;5;241m.\u001b[39mgrads[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grad_sampler' is not defined"
     ]
    }
   ],
   "source": [
    "params = grad_sampler.param_values[0].squeeze()\n",
    "grads = grad_sampler.grads[0].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472f2b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(16)\n",
    "fig.suptitle(\"Gradient estimators when true output is T\")\n",
    "ax1.set_title(\"With true parameter w = F\")\n",
    "ax1.set_xlim((0, 1))\n",
    "ax1.set_ylim((0, 2))\n",
    "plot_grads(params[sample_cjs][:,weights == False], grads[sample_cjs][:,weights == False], ax1)\n",
    "ax2.set_title(\"With true parameter w = T\")\n",
    "ax2.set_xlim((0, 1))\n",
    "ax2.set_ylim((0, 2))\n",
    "plot_grads(params[sample_cjs][:,weights], grads[sample_cjs][:,weights], ax2)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea5d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(16)\n",
    "fig.suptitle(\"Gradient estimators when true output is F\")\n",
    "ax1.set_title(\"With true parameter w = F\")\n",
    "ax1.set_xlim((0, 1))\n",
    "ax1.set_ylim((-2, 0))\n",
    "plot_grads(params[sample_cjs == False][:,weights == False], grads[sample_cjs == False][:,weights == False], ax1)\n",
    "ax2.set_title(\"With true parameter w = T\")\n",
    "ax2.set_xlim((0, 1))\n",
    "ax2.set_ylim((-2, 0))\n",
    "plot_grads(params[sample_cjs == False][:,weights], grads[sample_cjs == False][:,weights], ax2)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f34d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(16)\n",
    "fig.suptitle(\"Gradient estimators overall\")\n",
    "ax1.set_title(\"With true parameter w = F\")\n",
    "ax1.set_xlim((0, 1))\n",
    "plot_grads(params[:,weights == False], grads[:,weights == False], ax1, no_points=True)\n",
    "ax2.set_title(\"With true parameter w = T\")\n",
    "ax2.set_xlim((0, 1))\n",
    "plot_grads(params[:,weights], grads[:,weights], ax2, no_points=True)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1532f523",
   "metadata": {},
   "source": [
    "The above results also show that the default behaviour is to slowly ascend parameters to 1, so we would expect parameters with true parameterisation $T$ to be faithfully captured also. We now train a model to verify our expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f449cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(cj_model.parameters(), lr=1e-3)\n",
    "\n",
    "losses = []\n",
    "torch.autograd.set_detect_anomaly(True) \n",
    "\n",
    "for bs in loader:\n",
    "    cjs = logic.conjoin(logic.implies(weights, bs), dim=1)\n",
    "    cj_hats = cj_model(flogic.encode(bs)).squeeze()\n",
    "    loss = ((cjs.float() - cj_hats) ** 2).mean()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "losses = torch.Tensor(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd64ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a70a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "((torch.sigmoid(cj_model.weights).squeeze() - weights.float()) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71d7ea1",
   "metadata": {},
   "source": [
    "The average distance of the learnt parameters is incredibly close to the true ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b03c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cj_model.fuzzy_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff8609",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_dim100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dfc056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
