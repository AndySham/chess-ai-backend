\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Further Gradient Estimations}{26}{appendix.B}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{section:moregradients}{{B}{26}{Further Gradient Estimations}{appendix.B}{}}
\newlabel{fig:conjgrad2false}{{B.1a}{26}{Gradient samples for correct parameter $\F $\relax }{figure.caption.16}{}}
\newlabel{sub@fig:conjgrad2false}{{a}{26}{Gradient samples for correct parameter $\F $\relax }{figure.caption.16}{}}
\newlabel{fig:conjgrad2true}{{B.1b}{26}{Gradient samples for correct parameter $\T $\relax }{figure.caption.16}{}}
\newlabel{sub@fig:conjgrad2true}{{b}{26}{Gradient samples for correct parameter $\T $\relax }{figure.caption.16}{}}
\newlabel{fig:conjgrad2falseavg}{{B.1c}{26}{Mean gradient estimator for correct parameter $\F $\relax }{figure.caption.16}{}}
\newlabel{sub@fig:conjgrad2falseavg}{{c}{26}{Mean gradient estimator for correct parameter $\F $\relax }{figure.caption.16}{}}
\newlabel{fig:conjgrad2trueavg}{{B.1d}{26}{Mean gradient estimator for correct parameter $\T $\relax }{figure.caption.16}{}}
\newlabel{sub@fig:conjgrad2trueavg}{{d}{26}{Mean gradient estimator for correct parameter $\T $\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.1}{\ignorespaces Gradient estimations over the problem of real conjunctions with $\texttt  {XOR}$ loss $a=2$. We begin to see a separation between parameters, though the value of parameters with true value $\textbf  {F}$ seem to converge around 0.4, due to class imbalance.\relax }}{26}{figure.caption.16}\protected@file@percent }
\newlabel{fig:conjgrad2}{{B.1}{26}{Gradient estimations over the problem of real conjunctions with $\XOR $ loss $a=2$. We begin to see a separation between parameters, though the value of parameters with true value $\F $ seem to converge around 0.4, due to class imbalance.\relax }{figure.caption.16}{}}
\newlabel{fig:conjgrad10false}{{B.2a}{27}{Gradient samples for correct parameter $\F $\relax }{figure.caption.17}{}}
\newlabel{sub@fig:conjgrad10false}{{a}{27}{Gradient samples for correct parameter $\F $\relax }{figure.caption.17}{}}
\newlabel{fig:conjgrad10true}{{B.2b}{27}{Gradient samples for correct parameter $\T $\relax }{figure.caption.17}{}}
\newlabel{sub@fig:conjgrad10true}{{b}{27}{Gradient samples for correct parameter $\T $\relax }{figure.caption.17}{}}
\newlabel{fig:conjgrad10falseavg}{{B.2c}{27}{Mean gradient estimator for correct parameter $\F $\relax }{figure.caption.17}{}}
\newlabel{sub@fig:conjgrad10falseavg}{{c}{27}{Mean gradient estimator for correct parameter $\F $\relax }{figure.caption.17}{}}
\newlabel{fig:conjgrad10trueavg}{{B.2d}{27}{Mean gradient estimator for correct parameter $\T $\relax }{figure.caption.17}{}}
\newlabel{sub@fig:conjgrad10trueavg}{{d}{27}{Mean gradient estimator for correct parameter $\T $\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.2}{\ignorespaces Gradient estimations over the problem of real conjunctions with $\texttt  {XOR}$ loss $a=10$, Product logic, 10 dimensions. A much clearer separation between parameters.\relax }}{27}{figure.caption.17}\protected@file@percent }
\newlabel{fig:conjgrad10}{{B.2}{27}{Gradient estimations over the problem of real conjunctions with $\XOR $ loss $a=10$, Product logic, 10 dimensions. A much clearer separation between parameters.\relax }{figure.caption.17}{}}
\newlabel{fig:conjgrad10falsess}{{B.3a}{28}{Gradient samples for correct parameter $\F $\relax }{figure.caption.18}{}}
\newlabel{sub@fig:conjgrad10falsess}{{a}{28}{Gradient samples for correct parameter $\F $\relax }{figure.caption.18}{}}
\newlabel{fig:conjgrad10truess}{{B.3b}{28}{Gradient samples for correct parameter $\T $\relax }{figure.caption.18}{}}
\newlabel{sub@fig:conjgrad10truess}{{b}{28}{Gradient samples for correct parameter $\T $\relax }{figure.caption.18}{}}
\newlabel{fig:conjgrad10falseavgss}{{B.3c}{28}{Mean gradient estimator for correct parameter $\F $\relax }{figure.caption.18}{}}
\newlabel{sub@fig:conjgrad10falseavgss}{{c}{28}{Mean gradient estimator for correct parameter $\F $\relax }{figure.caption.18}{}}
\newlabel{fig:conjgrad10trueavgss}{{B.3d}{28}{Mean gradient estimator for correct parameter $\T $\relax }{figure.caption.18}{}}
\newlabel{sub@fig:conjgrad10trueavgss}{{d}{28}{Mean gradient estimator for correct parameter $\T $\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.3}{\ignorespaces Gradient estimations over the problem of real conjunctions with $\texttt  {XOR}$ loss $a=10$, Schweizer-Sklar logic $p=-2$, 10 dimensions. Note that the size of the gradient estimator is an order of magnitude larger than Product logic for inferences.\relax }}{28}{figure.caption.18}\protected@file@percent }
\newlabel{fig:conjgrad10ss}{{B.3}{28}{Gradient estimations over the problem of real conjunctions with $\XOR $ loss $a=10$, Schweizer-Sklar logic $p=-2$, 10 dimensions. Note that the size of the gradient estimator is an order of magnitude larger than Product logic for inferences.\relax }{figure.caption.18}{}}
\newlabel{fig:conjgrad10false100}{{B.4a}{29}{Gradient samples for correct parameter $\F $\relax }{figure.caption.19}{}}
\newlabel{sub@fig:conjgrad10false100}{{a}{29}{Gradient samples for correct parameter $\F $\relax }{figure.caption.19}{}}
\newlabel{fig:conjgrad10true100}{{B.4b}{29}{Gradient samples for correct parameter $\T $\relax }{figure.caption.19}{}}
\newlabel{sub@fig:conjgrad10true100}{{b}{29}{Gradient samples for correct parameter $\T $\relax }{figure.caption.19}{}}
\newlabel{fig:conjgrad10falseavg100}{{B.4c}{29}{Mean gradient estimator for correct parameter $\F $\relax }{figure.caption.19}{}}
\newlabel{sub@fig:conjgrad10falseavg100}{{c}{29}{Mean gradient estimator for correct parameter $\F $\relax }{figure.caption.19}{}}
\newlabel{fig:conjgrad10trueavg100}{{B.4d}{29}{Mean gradient estimator for correct parameter $\T $\relax }{figure.caption.19}{}}
\newlabel{sub@fig:conjgrad10trueavg100}{{d}{29}{Mean gradient estimator for correct parameter $\T $\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.4}{\ignorespaces Gradient estimations over the problem of real conjunctions with $\texttt  {XOR}$ loss $a=10$, Product logic, 100 dimensions. A clear example of the curse of dimensionality applying to the vanishing gradient estimate.\relax }}{29}{figure.caption.19}\protected@file@percent }
\newlabel{fig:conjgrad10100}{{B.4}{29}{Gradient estimations over the problem of real conjunctions with $\XOR $ loss $a=10$, Product logic, 100 dimensions. A clear example of the curse of dimensionality applying to the vanishing gradient estimate.\relax }{figure.caption.19}{}}
\newlabel{fig:conjgrad10falsess100}{{B.5a}{30}{Gradient samples for correct parameter $\F $\relax }{figure.caption.20}{}}
\newlabel{sub@fig:conjgrad10falsess100}{{a}{30}{Gradient samples for correct parameter $\F $\relax }{figure.caption.20}{}}
\newlabel{fig:conjgrad10truess100}{{B.5b}{30}{Gradient samples for correct parameter $\T $\relax }{figure.caption.20}{}}
\newlabel{sub@fig:conjgrad10truess100}{{b}{30}{Gradient samples for correct parameter $\T $\relax }{figure.caption.20}{}}
\newlabel{fig:conjgrad10falseavgss100}{{B.5c}{30}{Mean gradient estimator for correct parameter $\F $\relax }{figure.caption.20}{}}
\newlabel{sub@fig:conjgrad10falseavgss100}{{c}{30}{Mean gradient estimator for correct parameter $\F $\relax }{figure.caption.20}{}}
\newlabel{fig:conjgrad10trueavgss100}{{B.5d}{30}{Mean gradient estimator for correct parameter $\T $\relax }{figure.caption.20}{}}
\newlabel{sub@fig:conjgrad10trueavgss100}{{d}{30}{Mean gradient estimator for correct parameter $\T $\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.5}{\ignorespaces Gradient estimations over the problem of real conjunctions with $\texttt  {XOR}$ loss $a=10$, Schweizer-Sklar logic $p=-2$, 100 dimensions. An example of Schweizer-Sklar logic being more adept against the curse of dimensionality, when making inferences.\relax }}{30}{figure.caption.20}\protected@file@percent }
\newlabel{fig:conjgrad10ss100}{{B.5}{30}{Gradient estimations over the problem of real conjunctions with $\XOR $ loss $a=10$, Schweizer-Sklar logic $p=-2$, 100 dimensions. An example of Schweizer-Sklar logic being more adept against the curse of dimensionality, when making inferences.\relax }{figure.caption.20}{}}
\newlabel{fig:conjgrad100falsebce}{{B.6a}{31}{Gradient samples for correct parameter $\F $\relax }{figure.caption.21}{}}
\newlabel{sub@fig:conjgrad100falsebce}{{a}{31}{Gradient samples for correct parameter $\F $\relax }{figure.caption.21}{}}
\newlabel{fig:conjgrad100truebce}{{B.6b}{31}{Gradient samples for correct parameter $\T $\relax }{figure.caption.21}{}}
\newlabel{sub@fig:conjgrad100truebce}{{b}{31}{Gradient samples for correct parameter $\T $\relax }{figure.caption.21}{}}
\newlabel{fig:conjgrad100falseavgbce}{{B.6c}{31}{Mean gradient estimator for correct parameter $\F $\relax }{figure.caption.21}{}}
\newlabel{sub@fig:conjgrad100falseavgbce}{{c}{31}{Mean gradient estimator for correct parameter $\F $\relax }{figure.caption.21}{}}
\newlabel{fig:conjgrad100trueavgbce}{{B.6d}{31}{Mean gradient estimator for correct parameter $\T $\relax }{figure.caption.21}{}}
\newlabel{sub@fig:conjgrad100trueavgbce}{{d}{31}{Mean gradient estimator for correct parameter $\T $\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.6}{\ignorespaces Gradient estimations over the problem of real conjunctions with binary cross-entropy loss, Product logic, 100 dimensions. Although improved over $\texttt  {XOR}$ loss, we still observe the curse of dimensionality.\relax }}{31}{figure.caption.21}\protected@file@percent }
\newlabel{fig:conjgrad100bce}{{B.6}{31}{Gradient estimations over the problem of real conjunctions with binary cross-entropy loss, Product logic, 100 dimensions. Although improved over $\XOR $ loss, we still observe the curse of dimensionality.\relax }{figure.caption.21}{}}
\newlabel{fig:conjgrad10falsessbce}{{B.7a}{32}{Gradient samples for correct parameter $\F $\relax }{figure.caption.22}{}}
\newlabel{sub@fig:conjgrad10falsessbce}{{a}{32}{Gradient samples for correct parameter $\F $\relax }{figure.caption.22}{}}
\newlabel{fig:conjgrad10truessbce}{{B.7b}{32}{Gradient samples for correct parameter $\T $\relax }{figure.caption.22}{}}
\newlabel{sub@fig:conjgrad10truessbce}{{b}{32}{Gradient samples for correct parameter $\T $\relax }{figure.caption.22}{}}
\newlabel{fig:conjgrad10falseavgssbce}{{B.7c}{32}{Mean gradient estimator for correct parameter $\F $\relax }{figure.caption.22}{}}
\newlabel{sub@fig:conjgrad10falseavgssbce}{{c}{32}{Mean gradient estimator for correct parameter $\F $\relax }{figure.caption.22}{}}
\newlabel{fig:conjgrad10trueavgssbce}{{B.7d}{32}{Mean gradient estimator for correct parameter $\T $\relax }{figure.caption.22}{}}
\newlabel{sub@fig:conjgrad10trueavgssbce}{{d}{32}{Mean gradient estimator for correct parameter $\T $\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.7}{\ignorespaces Gradient estimations over the problem of real conjunctions with binary cross-entropy loss, Schweizer-Sklar logic $p=-2$, 10 dimensions. An even better separation of gradients.\relax }}{32}{figure.caption.22}\protected@file@percent }
\newlabel{fig:conjgrad10ssbce}{{B.7}{32}{Gradient estimations over the problem of real conjunctions with binary cross-entropy loss, Schweizer-Sklar logic $p=-2$, 10 dimensions. An even better separation of gradients.\relax }{figure.caption.22}{}}
\newlabel{fig:conjgrad100falsessbce}{{B.8a}{33}{Gradient samples for correct parameter $\F $\relax }{figure.caption.23}{}}
\newlabel{sub@fig:conjgrad100falsessbce}{{a}{33}{Gradient samples for correct parameter $\F $\relax }{figure.caption.23}{}}
\newlabel{fig:conjgrad100truessbce}{{B.8b}{33}{Gradient samples for correct parameter $\T $\relax }{figure.caption.23}{}}
\newlabel{sub@fig:conjgrad100truessbce}{{b}{33}{Gradient samples for correct parameter $\T $\relax }{figure.caption.23}{}}
\newlabel{fig:conjgrad100falseavgssbce}{{B.8c}{33}{Mean gradient estimator for correct parameter $\F $\relax }{figure.caption.23}{}}
\newlabel{sub@fig:conjgrad100falseavgssbce}{{c}{33}{Mean gradient estimator for correct parameter $\F $\relax }{figure.caption.23}{}}
\newlabel{fig:conjgrad100trueavgssbce}{{B.8d}{33}{Mean gradient estimator for correct parameter $\T $\relax }{figure.caption.23}{}}
\newlabel{sub@fig:conjgrad100trueavgssbce}{{d}{33}{Mean gradient estimator for correct parameter $\T $\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.8}{\ignorespaces Gradient estimations over the problem of real conjunctions with binary cross-entropy loss, Schweizer-Sklar logic $p=-2$, 100 dimensions. Note the magnitude of the gradients has not suffered much at all.\relax }}{33}{figure.caption.23}\protected@file@percent }
\newlabel{fig:conjgrad100ssbce}{{B.8}{33}{Gradient estimations over the problem of real conjunctions with binary cross-entropy loss, Schweizer-Sklar logic $p=-2$, 100 dimensions. Note the magnitude of the gradients has not suffered much at all.\relax }{figure.caption.23}{}}
\newlabel{fig:conjgrad10falsem}{{B.9a}{34}{Gradient samples for correct parameter $\F $, $a=1$\relax }{figure.caption.24}{}}
\newlabel{sub@fig:conjgrad10falsem}{{a}{34}{Gradient samples for correct parameter $\F $, $a=1$\relax }{figure.caption.24}{}}
\newlabel{fig:conjgrad10truem}{{B.9b}{34}{Gradient samples for correct parameter $\T $, $a=1$\relax }{figure.caption.24}{}}
\newlabel{sub@fig:conjgrad10truem}{{b}{34}{Gradient samples for correct parameter $\T $, $a=1$\relax }{figure.caption.24}{}}
\newlabel{fig:conjgrad10falseavgm}{{B.9c}{34}{Gradient samples for correct parameter $\F $, $a=2$\relax }{figure.caption.24}{}}
\newlabel{sub@fig:conjgrad10falseavgm}{{c}{34}{Gradient samples for correct parameter $\F $, $a=2$\relax }{figure.caption.24}{}}
\newlabel{fig:conjgrad10trueavgm}{{B.9d}{34}{Gradient samples for correct parameter $\T $, $a=2$\relax }{figure.caption.24}{}}
\newlabel{sub@fig:conjgrad10trueavgm}{{d}{34}{Gradient samples for correct parameter $\T $, $a=2$\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.9}{\ignorespaces Gradient estimations over the problem of real conjunctions under $\texttt  {XOR}$ loss with different exponents. Minimum logic, 10 dimensions. An example of binarization of gradient estimates.\relax }}{34}{figure.caption.24}\protected@file@percent }
\newlabel{fig:conjgrad10m}{{B.9}{34}{Gradient estimations over the problem of real conjunctions under $\XOR $ loss with different exponents. Minimum logic, 10 dimensions. An example of binarization of gradient estimates.\relax }{figure.caption.24}{}}
\@setckpt{a2}{
\setcounter{page}{35}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{0}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{9}
\setcounter{table}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{3}
\setcounter{bookmark@seq@number}{30}
\setcounter{parentequation}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{caption@flags}{6}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{4}
\setcounter{subtable}{0}
\setcounter{NAT@ctr}{33}
\setcounter{section@level}{0}
}
